\section{Intermediate Representation}
\label{sec:ir}

In lieu of duplicating significant fragments of code to create an entirely separate intermediate representation (IR) to represent the AST, the IR instead extends the existing \texttt{Expression}s, by generating a mapping between the IR and the original or generated \texttt{Expression}.
The inheritance structure of the IR can be seen in \autoref{fig:ir_inheritance} - note that \texttt{Id} also extends \texttt{BindingPattern} and \texttt{PropertyDefinition} from the original TypeScript AST.
By augmenting the existing AST, a separate representation for other parts of the AST, such as statements or declarations, is not required.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[every node/.style={execute at end node=\vphantom{bg}}]
        \node[black!50] at (0, 0) (atom) {\texttt{Atom}};
        \node[black!50, right=of atom] (id) {\texttt{Id}};
        \node[right=of id] (comb) {\texttt{Combinator}};
        \node[right=of comb] (func) {\texttt{Func}};
        \node[black!50, right=of func] (irli) {\texttt{IRLiteral}};
        \node[right=of irli] (gene) {\texttt{Generated}};
        \node (p0) at ($(atom.west)!0.5!(gene.east)$) {};
        \node[] (spec) at (gene |- 0, -1) {\texttt{Special}};
        \node[left=of spec] (gf) {\texttt{GeneratedFunc}};
        \node[] (ir) at (p0 |- 0, 1) {\texttt{IR}};
        \node[] (expr) at (p0 |- 0, 2) {\itshape \texttt{Expression}};
        \draw
        (expr) edge[->] (ir)
        (ir) edge[->, bend right=15] (atom)
        (ir) edge[->, bend right=10] (id)
        (ir) edge[->, bend right=5] (comb)
        (ir) edge[->, bend left=5] (func)
        (ir) edge[->, bend left=10] (irli)
        (ir) edge[->, bend left=15] (gene)
        (gene) edge[->] (spec)
        (gene) edge[->, bend right=5] (gf);
    \end{tikzpicture}
    \caption{Inheritance hierarchy within the IR, nodes in \textcolor{black!50}{\texttt{grey}} are concrete whereas nodes in \texttt{black} are traits}
    \label{fig:ir_inheritance}
\end{figure}

\texttt{Atom}s contain a unique numeric identifier which provides a mapping from an \texttt{Atom} to an \texttt{Expression}, which is stored in a mutable state (implicitly used by all pipeline stages).
These contain any \texttt{Expression}s that cannot be changed into any other representation.
Generally, they contain nodes that require no further inspection, as they are unlikely to contain any combinators - especially not ones that can be meaningfully inspected.

On the other hand, \texttt{Combinator}s are a special case of regular binary operators which contain combinators (any other operation will be converted into an \texttt{Atom}).
For each different combinator, there is a different concrete implementation (\texttt{case class}), allowing for easier inspection in subsequent pipeline stages (via matching on a specific combinator, rather than checking which operation is being performed manually).
Each of these combinators has two arguments, both of which are also IRs.
Similarly, \texttt{Func}s have concrete implementations for reserved functions that are provided with the TypeScript library; these have specific arguments which are assumed to be valid when processing.
This adds the ability to perform some inspection on functions which have known behaviours.

\texttt{Id} and \texttt{IRLiteral} both have similar functionality in that they wrap existing nodes (namely, \texttt{Identifier} and \texttt{Literal}) to work within the IR.
The former is handled separately as it can often be useful to be able to directly access variable names in later stages without the need to reference the shared state (if they were instead represented as \texttt{Atom}s).
On the other hand, \texttt{IRLiteral}s are used for a similar reason, however the main purpose is to allow for inspection into string or character literals, which is useful for subsequent stages.

Finally, the \texttt{Generated} trait refers to any nodes without a mapping from an \texttt{Expression}, meaning that they are only generated by the processing pipeline.
This is further divided into one of two traits.
Nodes which extend the \texttt{GeneratedFunc} trait represent functions that are applied to IR nodes.
These functions have a `fallback' implementation within the library; however, the preprocessor will attempt to directly alter the AST whenever possible.
In contrast, nodes which extend the \texttt{Special} trait are typically used to represent specific values or are used to directly pass information to other stages.
For example, it may be required to explicitly pass an \texttt{Expression} forward without any modifications or highlight characters which exist in the first set of a parser.
\bigskip

The example of addition from \autoref{lst:running_example}, after being parsed into the AST shown in \autoref{lst:running_ast}, is translated into the IR as shown in \autoref{lst:running_ir}.
Notice how only the information that is directly related to parsers is maintained, whereas the function is simply converted into \texttt{Atom(0)}.

\begin{capminted}
    \begin{minted}{scala}
        (Id("expr") <**> (Atom(0) <$ Chr(IRLiteral("'+'"))) <*> Id("nat")) <|>
        Id("nat")
    \end{minted}
    \vspace{-0.5\baselineskip}
    \caption{IR of right-hand side of assignment}
    \label{lst:running_ir}
\end{capminted}

\subsection{Function Rewriting}
\label{ssec:func_rewrite}
An example of the function rewriting is as follows, where \texttt{f0} is a function without AST rewriting (uses library functions) and \texttt{f1} is a function that is directly rewritten.
While this may seem like a pathological example, these transformations are used extensively when rewriting the parsers to support left-recursion.

\begin{capminted}
    \begin{minted}{typescript}
        let f0 = flip(curry(unpairFirstArg(
            ([x, y]: [number, number], z: number) => x + y - z
        )));
        let f1 = ([y, z]: [number, number]) => (x: number) => x + y - z;
    \end{minted}
    \vspace{-0.5\baselineskip}
    \caption{Example of function rewriting performed by the preprocessor}
    \label{lst:rewrite_xyz}
\end{capminted}

Not only does the direct rewrite improve code clarity by omitting multiple function calls, there is also a small but measurable performance uplift stemming from the reduced number of invocations.
This can be seen in \autoref{fig:rewrite}, which performs $10,000$ iterations of the function in \autoref{lst:rewrite_xyz}.
Within each iteration, the function is transformed and executed $n$ times.
This result demonstrates that with repeated invocations, the performance gap between the two forms becomes narrower.
However, the directly rewritten form consistently performs better, especially with few invocations when it can complete execution in approximately half the time.

\begin{figure}[H]
    \centering
    \import{figs}{figs/gen_func_rewrite.pgf}
    \vspace{-0.5\baselineskip}
    \caption{Change in average execution time based on number of repetitions}
    \label{fig:rewrite}
\end{figure}
